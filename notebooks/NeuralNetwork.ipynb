{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43bd5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7aea83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load(\"X_train.th\")\n",
    "y_train = torch.load(\"y_train.th\").to(torch.int64)\n",
    "y_train_one_hot = F.one_hot(y_train, num_classes=5).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a875c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SIZE_ORDER_SEQUENCE = 183\n",
    "FEATURE_SIZE_BRAND = 100\n",
    "FEATURE_SIZE_F_1 = 12\n",
    "FEATURE_SIZE_F_2 = 4\n",
    "FEATURE_SIZE_F_3 = 100\n",
    "FEATURE_SIZE_F_4 = 6\n",
    "FEATURE_SIZE_F_5 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "738863e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_order_sequence = nn.Linear(FEATURE_SIZE_ORDER_SEQUENCE, 20)\n",
    "        self.encoder_brand = nn.Linear(FEATURE_SIZE_BRAND, 20)\n",
    "        self.encoder_f_3 = nn.Linear(FEATURE_SIZE_F_3, 20)\n",
    "        self.encoder_f_5 = nn.Linear(FEATURE_SIZE_F_5, 20)\n",
    "        \n",
    "        self.ff1 = nn.Linear(\n",
    "            4*20 + FEATURE_SIZE_F_1 + FEATURE_SIZE_F_2 + FEATURE_SIZE_F_4, 50\n",
    "        )\n",
    "        self.ff2 = nn.Linear(50, 5)\n",
    "        \n",
    "        self.start_idxs = torch.cumsum(torch.Tensor([\n",
    "            0, FEATURE_SIZE_ORDER_SEQUENCE, FEATURE_SIZE_BRAND, FEATURE_SIZE_F_1, FEATURE_SIZE_F_2,\n",
    "            FEATURE_SIZE_F_3, FEATURE_SIZE_F_4\n",
    "        ]), dim=0).int()\n",
    "        self.end_idxs = torch.cumsum(torch.Tensor([\n",
    "            FEATURE_SIZE_ORDER_SEQUENCE, FEATURE_SIZE_BRAND, FEATURE_SIZE_F_1, FEATURE_SIZE_F_2,\n",
    "            FEATURE_SIZE_F_3, FEATURE_SIZE_F_4, FEATURE_SIZE_F_5\n",
    "        ]), dim=0).int()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inputs = []\n",
    "        for start_idx, end_idx in zip(self.start_idxs, self.end_idxs):\n",
    "            inputs.append(x[:, start_idx:end_idx])\n",
    "        x = torch.hstack([\n",
    "            self.encoder_order_sequence(inputs[0]), \n",
    "            self.encoder_brand(inputs[1]), \n",
    "            inputs[2], \n",
    "            inputs[3],\n",
    "            self.encoder_f_3(inputs[4]), \n",
    "            inputs[5], \n",
    "            self.encoder_f_5(inputs[6]),  \n",
    "        ])        \n",
    "        \n",
    "        x = nn.ReLU()(self.ff1(x))\n",
    "        #x = nn.ReLU()(self.ff2(x))\n",
    "        x = nn.Softmax(dim=1)(self.ff2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a33059d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2bff875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:23<00:00, 40.74s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "losses = []\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    episode_loss = 0\n",
    "    for data_point, target in zip(X_train, y_train_one_hot):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data_point.reshape(1, -1))\n",
    "        loss = loss_fn(pred, target.reshape(1, -1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        episode_loss += loss.item() / X_train.shape[0]\n",
    "    losses.append(episode_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3f621125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2703041239479187,\n",
       " 1.267582491399523,\n",
       " 1.267582491399523,\n",
       " 1.267582491399523,\n",
       " 1.267582491399523]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fcf89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_distr = torch.zeros(5)\n",
    "\n",
    "for data_point, target in zip(X_train, y_train_one_hot):\n",
    "    pred = model(data_point.reshape(1, -1))[0]\n",
    "    pred_distr[torch.where(pred == 1)[0][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4eaca356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9745.,    0.,    0.,    0.,    0.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec53ae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000e+00, 5.9010e-12, 1.0237e-11, 5.3830e-12, 4.0505e-12],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([0., 1., 0., 0., 0.]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ed5ecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f32de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
